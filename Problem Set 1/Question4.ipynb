{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script involves the Boston.csv data set. We want to predict per capita crime rate using the other variables in the data set. In other words, per capita crime rate si the response, and the other variables are the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruotwang/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             crim          zn       indus        chas         nox          rm  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              age         dis         rad         tax     ptratio       black  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "            lstat        medv  \n",
      "count  506.000000  506.000000  \n",
      "mean    12.653063   22.532806  \n",
      "std      7.141062    9.197104  \n",
      "min      1.730000    5.000000  \n",
      "25%      6.950000   17.025000  \n",
      "50%     11.360000   21.200000  \n",
      "75%     16.955000   25.000000  \n",
      "max     37.970000   50.000000  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/Boston.csv')\n",
    "df = df.drop('index', axis=1)\n",
    "description = df.describe()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(a) For each predictor, fit a simple linear regression model to predict the response. Describe your results. In which of the models is there a statistically significant association between the predictor and the response? Create some plots to back up your assertions.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(b) Fit a multiple regression model to predict the response using all of the predictors. Describe your results. For which predictors can we reject the null hypothesis H0 : βj = 0?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.741\n",
      "Model:                            OLS   Adj. R-squared:                  0.734\n",
      "Method:                 Least Squares   F-statistic:                     108.1\n",
      "Date:                Tue, 03 Oct 2017   Prob (F-statistic):          6.72e-135\n",
      "Time:                        18:06:21   Log-Likelihood:                -1498.8\n",
      "No. Observations:                 506   AIC:                             3026.\n",
      "Df Residuals:                     492   BIC:                             3085.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     36.4595      5.103      7.144      0.000      26.432      46.487\n",
      "crim          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
      "zn             0.0464      0.014      3.382      0.001       0.019       0.073\n",
      "indus          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
      "chas           2.6867      0.862      3.118      0.002       0.994       4.380\n",
      "nox          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
      "rm             3.8099      0.418      9.116      0.000       2.989       4.631\n",
      "age            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
      "dis           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
      "rad            0.3060      0.066      4.613      0.000       0.176       0.436\n",
      "tax           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
      "ptratio       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
      "black          0.0093      0.003      3.467      0.001       0.004       0.015\n",
      "lstat         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
      "==============================================================================\n",
      "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
      "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
      "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS.from_formula('medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat', df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table, we can see both 'indus'(0.738) and 'age'(0.958) have not statistically significant p-value, which need to be excluded.\n",
    "\n",
    "So we can reject null hypothesis for 'crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(c) How do your results from (a) compare to your results from (b)? Create a plot dis- playing the univariate regression coefficients from (a) on the x-axis, and the multiple regression coefficients from (b) on the y-axis. That is, each predictor is displayed as a single point in the plot. Its coefficient in a simple linear regression model is shown on the x-axis, and its coefficient estimate in the multiple linear regression model is shown on the y-axis.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(d) Is there evidence of non-linear association between any of the predictors and the response? To answer this question, for each predictor x, fit a model of the form\n",
    "\n",
    "                                y = β0 + β1x1 + β2x2 + β3x3 + ε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
